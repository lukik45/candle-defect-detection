{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 10:44:32.270915: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input, RepeatVector, TimeDistributed, SimpleRNN\n",
    "from tensorflow.keras.layers import Reshape, GlobalMaxPool1D, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 10:44:36.038989: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-12-30 10:44:36.039115: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Lucky\n",
      "2022-12-30 10:44:36.039155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Lucky\n",
      "2022-12-30 10:44:36.039525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.60.11\n",
      "2022-12-30 10:44:36.039648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.60.11\n",
      "2022-12-30 10:44:36.039686: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.60.11\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/xl.pickle', 'rb') as xl_file:\n",
    "    xl = (pickle.load(xl_file))\n",
    "\n",
    "with open('./data/yl.pickle', 'rb') as yl_file:\n",
    "    yl = pickle.load(yl_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "There are 50000 records. Each record is a sequence of outputs from 3 sensors.\n",
    "Each record is multi-labeled, there are 5 types of defects and they are nonexclusive.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'sequence': xl,\n",
    "        'defects' : yl\n",
    "    }\n",
    ")\n",
    "df['seq_len'] = df.sequence.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal length of a sequence: 40\n",
      "maximal length of a sequence: 59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'minimal length of a sequence: {min(df.seq_len)}')\n",
    "print(f'maximal length of a sequence: {max(df.seq_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.seq_len.hist(grid=False, bins=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with the data\n",
    "\n",
    "#### 1. Training examples vary in length\n",
    "We can solve this issue with the following approaches:\n",
    "1. Truncate each training example (then each example has the same lenght and we can easily train our models)\n",
    "Drawbacks:\n",
    "- information loss\n",
    "- labeling errors (if a defect is present in a part of the sequence that has been truncated, then we introduce noise to the data)\n",
    "\n",
    "2. Write custom data generator that will feed the network with training batches having the same number of samples in each example. (Within a single batch, each training example has to have equal shape, but between batches shapes may vary)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "We will use the same splits for all the models, to be able to compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:40000]\n",
    "df_val = df.iloc[40000:45000]\n",
    "df_test = df.iloc[45000:]\n",
    "\n",
    "# defining test array\n",
    "y_test = np.stack(df_test.defects, axis=0).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st approach - truncating the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_trunc = df_train.copy()\n",
    "df_train_trunc.sequence = [sample[:40] for sample in df_train_trunc.sequence]\n",
    "\n",
    "df_val_trunc = df_val.copy()\n",
    "df_val_trunc.sequence = [sample[:40] for sample in df_val_trunc.sequence]\n",
    "\n",
    "df_test_trunc = df_test.copy()\n",
    "df_test_trunc.sequence = [sample[:40] for sample in df_test_trunc.sequence]\n",
    "\n",
    "\n",
    "X_train_trunc = np.stack(df_train_trunc.sequence, axis=0)\n",
    "y_train_trunc = np.stack(df_train_trunc.defects, axis=0)\n",
    "\n",
    "X_val_trunc = np.stack(df_val_trunc.sequence, axis=0)\n",
    "y_val_trunc = np.stack(df_val_trunc.defects, axis=0)\n",
    "\n",
    "X_test_trunc = np.stack(df_test_trunc.sequence, axis=0)\n",
    "y_test_trunc = np.stack(df_test_trunc.defects, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(None, 3))) # return_seq = False now\n",
    "model.add(Dense(5, 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', metrics='acc', optimizer='adam')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 4s 5ms/step - loss: 0.3795 - acc: 0.4113 - val_loss: 0.3042 - val_acc: 0.4126\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2892 - acc: 0.4588 - val_loss: 0.2510 - val_acc: 0.5506\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2514 - acc: 0.4885 - val_loss: 0.2314 - val_acc: 0.4900\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2343 - acc: 0.4878 - val_loss: 0.2165 - val_acc: 0.4960\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2210 - acc: 0.4971 - val_loss: 0.2054 - val_acc: 0.4742\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2113 - acc: 0.5018 - val_loss: 0.2007 - val_acc: 0.4616\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2016 - acc: 0.5106 - val_loss: 0.2139 - val_acc: 0.6264\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1939 - acc: 0.5093 - val_loss: 0.1873 - val_acc: 0.4668\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1872 - acc: 0.5148 - val_loss: 0.1783 - val_acc: 0.4984\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1805 - acc: 0.5137 - val_loss: 0.1833 - val_acc: 0.4894\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1754 - acc: 0.5228 - val_loss: 0.1697 - val_acc: 0.5260\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1711 - acc: 0.5265 - val_loss: 0.1753 - val_acc: 0.4958\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1689 - acc: 0.5287 - val_loss: 0.1603 - val_acc: 0.5010\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1640 - acc: 0.5336 - val_loss: 0.1560 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1610 - acc: 0.5357 - val_loss: 0.1554 - val_acc: 0.4876\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1583 - acc: 0.5406 - val_loss: 0.1562 - val_acc: 0.5402\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1555 - acc: 0.5425 - val_loss: 0.1456 - val_acc: 0.5042\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1523 - acc: 0.5428 - val_loss: 0.1489 - val_acc: 0.6472\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1492 - acc: 0.5500 - val_loss: 0.1474 - val_acc: 0.6070\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1463 - acc: 0.5585 - val_loss: 0.1409 - val_acc: 0.5228\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1474 - acc: 0.5626 - val_loss: 0.1418 - val_acc: 0.6410\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1443 - acc: 0.5666 - val_loss: 0.1401 - val_acc: 0.5758\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1423 - acc: 0.5681 - val_loss: 0.1357 - val_acc: 0.5382\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1416 - acc: 0.5697 - val_loss: 0.1392 - val_acc: 0.5324\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1400 - acc: 0.5795 - val_loss: 0.1319 - val_acc: 0.6604\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1409 - acc: 0.5777 - val_loss: 0.1358 - val_acc: 0.6410\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1394 - acc: 0.5684 - val_loss: 0.1350 - val_acc: 0.6314\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1355 - acc: 0.5688 - val_loss: 0.1281 - val_acc: 0.6258\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1342 - acc: 0.5764 - val_loss: 0.1319 - val_acc: 0.6622\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1336 - acc: 0.5828 - val_loss: 0.1292 - val_acc: 0.6898\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1320 - acc: 0.5816 - val_loss: 0.1267 - val_acc: 0.6486\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1325 - acc: 0.5854 - val_loss: 0.1272 - val_acc: 0.6048\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1359 - acc: 0.5820 - val_loss: 0.1282 - val_acc: 0.6620\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1297 - acc: 0.5961 - val_loss: 0.1281 - val_acc: 0.5144\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1323 - acc: 0.5777 - val_loss: 0.1251 - val_acc: 0.5446\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1287 - acc: 0.5749 - val_loss: 0.1246 - val_acc: 0.6374\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1282 - acc: 0.5827 - val_loss: 0.1313 - val_acc: 0.6060\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1272 - acc: 0.5861 - val_loss: 0.1249 - val_acc: 0.7010\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1268 - acc: 0.5832 - val_loss: 0.1252 - val_acc: 0.5538\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1291 - acc: 0.5793 - val_loss: 0.1270 - val_acc: 0.6322\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1265 - acc: 0.5908 - val_loss: 0.1233 - val_acc: 0.5262\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1252 - acc: 0.5849 - val_loss: 0.1228 - val_acc: 0.5352\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1260 - acc: 0.5763 - val_loss: 0.1245 - val_acc: 0.5848\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1248 - acc: 0.5873 - val_loss: 0.1227 - val_acc: 0.5720\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1260 - acc: 0.5846 - val_loss: 0.1224 - val_acc: 0.5784\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1247 - acc: 0.5864 - val_loss: 0.1221 - val_acc: 0.5198\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.1267 - acc: 0.5853 - val_loss: 0.1251 - val_acc: 0.6396\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.1261 - acc: 0.5868 - val_loss: 0.1211 - val_acc: 0.5280\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1237 - acc: 0.5700 - val_loss: 0.1212 - val_acc: 0.6538\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1235 - acc: 0.5945 - val_loss: 0.1215 - val_acc: 0.5486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5691e5f90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = EarlyStopping(patience=10)\n",
    "\n",
    "model.fit(X_train_trunc, y_train_trunc, validation_data=(X_val_trunc, y_val_trunc), batch_size=64, epochs=50, callbacks=[early])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 17s 3ms/step\n",
      "5000/5000 [==============================] - 26s 5ms/step - loss: 0.1574 - acc: 0.6590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15743444859981537, 0.6589999794960022]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(testGenerator).round().astype(int)\n",
    "model.evaluate(testGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3730,    6],\n",
       "        [  14, 1250]],\n",
       "\n",
       "       [[3754,   11],\n",
       "        [  15, 1220]],\n",
       "\n",
       "       [[3072,  690],\n",
       "        [  20, 1218]],\n",
       "\n",
       "       [[3740,    1],\n",
       "        [  21, 1238]],\n",
       "\n",
       "       [[3724,    0],\n",
       "        [   0, 1276]]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cf = multilabel_confusion_matrix(y_test, y_pred, samplewise=False)\n",
    "cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        def1       1.00      0.99      0.99      1264\n",
      "        def2       0.99      0.99      0.99      1235\n",
      "        def3       0.64      0.98      0.77      1238\n",
      "        def4       1.00      0.98      0.99      1259\n",
      "        def5       1.00      1.00      1.00      1276\n",
      "\n",
      "   micro avg       0.90      0.99      0.94      6272\n",
      "   macro avg       0.92      0.99      0.95      6272\n",
      "weighted avg       0.93      0.99      0.95      6272\n",
      " samples avg       0.73      0.76      0.74      6272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.astype(int), y_pred, target_names=['def1','def2','def3','def4','def5'], zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach we obtain very high precision, but average recall is `0.86`. Low recall may be caused by truncating parts of sequences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd approach - feed the NN with batches containing sequences of the same length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, batchSize=64, shuffle=True):\n",
    "    \n",
    "        self.batchSize = batchSize\n",
    "        self.shuffle = shuffle\n",
    "        self.df = df\n",
    "        self.indicies_dict = df.groupby('seq_len').indices\n",
    "        self.batches = []\n",
    "        self.generate_batches()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        '''This function is called at the end of each epoch'''\n",
    "        self.batches = []\n",
    "        self.generate_batches()\n",
    "            \n",
    "    def generate_batches(self):\n",
    "        \"\"\"At the end of each epoch, generate new batches of indices\"\"\"\n",
    "        for key, value in self.indicies_dict.items():\n",
    "            if self.shuffle:\n",
    "                random.shuffle(value)\n",
    "            splitted = np.array_split(value, len(value)//self.batchSize) # FIXME\n",
    "            self.batches += splitted[:-1]\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns one batch.\n",
    "        One batch contains the set of sequences of the same length\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        x = np.stack(self.df.iloc[self.batches[index], 0], axis=0)\n",
    "        y = np.stack(self.df.iloc[self.batches[index], 1], axis=0)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(Sequence):\n",
    "    \"\"\"Data generator that passes samples one by one, without shuffling\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(inplace=False, drop=True)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        '''This function is called at the end of each epoch'''\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return np.expand_dims(self.df.iloc[index, 0], axis=0), self.df.iloc[index, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>defects</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.25778191141323037, 0.4816766587494004, 0.2...</td>\n",
       "      <td>[True, False, False, False, True]</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.7837637256859469, 0.641783855343466, 0.632...</td>\n",
       "      <td>[False, True, False, False, True]</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.15060546518715953, 0.24562548151974692, 0....</td>\n",
       "      <td>[False, False, False, False, True]</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.4733923774063066, 0.1612727479939526, 0.25...</td>\n",
       "      <td>[False, False, False, False, False]</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.7086933605799737, 0.8808554239156839, 0.69...</td>\n",
       "      <td>[True, False, False, False, True]</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  [[0.25778191141323037, 0.4816766587494004, 0.2...   \n",
       "1  [[0.7837637256859469, 0.641783855343466, 0.632...   \n",
       "2  [[0.15060546518715953, 0.24562548151974692, 0....   \n",
       "3  [[0.4733923774063066, 0.1612727479939526, 0.25...   \n",
       "4  [[0.7086933605799737, 0.8808554239156839, 0.69...   \n",
       "\n",
       "                               defects  seq_len  \n",
       "0    [True, False, False, False, True]       48  \n",
       "1    [False, True, False, False, True]       47  \n",
       "2   [False, False, False, False, True]       59  \n",
       "3  [False, False, False, False, False]       58  \n",
       "4    [True, False, False, False, True]       50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainGenerator = DataGenerator(df_train)\n",
    "valGenerator = DataGenerator(df_val, batchSize=16)\n",
    "testGenerator = TestDataGenerator(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(64, input_shape=(None, 3))) # return_seq = False now\n",
    "model3.add(Dense(5, 'sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', metrics='acc', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "595/595 [==============================] - 7s 8ms/step - loss: 0.3689 - acc: 0.3519 - val_loss: 0.2906 - val_acc: 0.4967\n",
      "Epoch 2/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.2769 - acc: 0.4606 - val_loss: 0.2866 - val_acc: 0.3685\n",
      "Epoch 3/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.2345 - acc: 0.4596 - val_loss: 0.2121 - val_acc: 0.4751\n",
      "Epoch 4/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.2024 - acc: 0.4635 - val_loss: 0.2152 - val_acc: 0.5292\n",
      "Epoch 5/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1882 - acc: 0.4696 - val_loss: 0.1481 - val_acc: 0.4858\n",
      "Epoch 6/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1609 - acc: 0.4727 - val_loss: 0.1440 - val_acc: 0.5392\n",
      "Epoch 7/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1381 - acc: 0.4845 - val_loss: 0.1158 - val_acc: 0.5063\n",
      "Epoch 8/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1181 - acc: 0.4907 - val_loss: 0.1198 - val_acc: 0.4971\n",
      "Epoch 9/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1099 - acc: 0.5005 - val_loss: 0.1086 - val_acc: 0.4764\n",
      "Epoch 10/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.1035 - acc: 0.4979 - val_loss: 0.0772 - val_acc: 0.5202\n",
      "Epoch 11/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0838 - acc: 0.4986 - val_loss: 0.0780 - val_acc: 0.4798\n",
      "Epoch 12/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0813 - acc: 0.5012 - val_loss: 0.0680 - val_acc: 0.5151\n",
      "Epoch 13/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0706 - acc: 0.5026 - val_loss: 0.0703 - val_acc: 0.5146\n",
      "Epoch 14/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0655 - acc: 0.5032 - val_loss: 0.0777 - val_acc: 0.5121\n",
      "Epoch 15/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0565 - acc: 0.5072 - val_loss: 0.0508 - val_acc: 0.4928\n",
      "Epoch 16/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0604 - acc: 0.5067 - val_loss: 0.0593 - val_acc: 0.4693\n",
      "Epoch 17/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0482 - acc: 0.4972 - val_loss: 0.0509 - val_acc: 0.4854\n",
      "Epoch 18/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0448 - acc: 0.4954 - val_loss: 0.0455 - val_acc: 0.4800\n",
      "Epoch 19/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0435 - acc: 0.5037 - val_loss: 0.0411 - val_acc: 0.4948\n",
      "Epoch 20/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0404 - acc: 0.4961 - val_loss: 0.0356 - val_acc: 0.4740\n",
      "Epoch 21/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0444 - acc: 0.5044 - val_loss: 0.0499 - val_acc: 0.5550\n",
      "Epoch 22/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0324 - acc: 0.5008 - val_loss: 0.0310 - val_acc: 0.4849\n",
      "Epoch 23/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0302 - acc: 0.4973 - val_loss: 0.0251 - val_acc: 0.5020\n",
      "Epoch 24/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0297 - acc: 0.5106 - val_loss: 0.0280 - val_acc: 0.4916\n",
      "Epoch 25/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0340 - acc: 0.5096 - val_loss: 0.0211 - val_acc: 0.4937\n",
      "Epoch 26/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0238 - acc: 0.5023 - val_loss: 0.0252 - val_acc: 0.4804\n",
      "Epoch 27/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0255 - acc: 0.5056 - val_loss: 0.0206 - val_acc: 0.5035\n",
      "Epoch 28/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0210 - acc: 0.5061 - val_loss: 0.0186 - val_acc: 0.5029\n",
      "Epoch 29/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0222 - acc: 0.5139 - val_loss: 0.0186 - val_acc: 0.4873\n",
      "Epoch 30/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0180 - acc: 0.5057 - val_loss: 0.0204 - val_acc: 0.5181\n",
      "Epoch 31/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0205 - acc: 0.5224 - val_loss: 0.0221 - val_acc: 0.5253\n",
      "Epoch 32/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0156 - acc: 0.5214 - val_loss: 0.0138 - val_acc: 0.5277\n",
      "Epoch 33/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0215 - acc: 0.5341 - val_loss: 0.0150 - val_acc: 0.5110\n",
      "Epoch 34/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0135 - acc: 0.5245 - val_loss: 0.0180 - val_acc: 0.5127\n",
      "Epoch 35/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0152 - acc: 0.5286 - val_loss: 0.0195 - val_acc: 0.5456\n",
      "Epoch 36/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0131 - acc: 0.5300 - val_loss: 0.0118 - val_acc: 0.5349\n",
      "Epoch 37/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0134 - acc: 0.5378 - val_loss: 0.0396 - val_acc: 0.5279\n",
      "Epoch 38/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0147 - acc: 0.5649 - val_loss: 0.0119 - val_acc: 0.5245\n",
      "Epoch 39/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0112 - acc: 0.5405 - val_loss: 0.0123 - val_acc: 0.5525\n",
      "Epoch 40/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0106 - acc: 0.5473 - val_loss: 0.0107 - val_acc: 0.5732\n",
      "Epoch 41/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0132 - acc: 0.5447 - val_loss: 0.0106 - val_acc: 0.6375\n",
      "Epoch 42/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0095 - acc: 0.5672 - val_loss: 0.0157 - val_acc: 0.5339\n",
      "Epoch 43/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0088 - acc: 0.5454 - val_loss: 0.0070 - val_acc: 0.5377\n",
      "Epoch 44/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0093 - acc: 0.5531 - val_loss: 0.0097 - val_acc: 0.6059\n",
      "Epoch 45/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0132 - acc: 0.5815 - val_loss: 0.0810 - val_acc: 0.7457\n",
      "Epoch 46/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0128 - acc: 0.6153 - val_loss: 0.0075 - val_acc: 0.6469\n",
      "Epoch 47/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0079 - acc: 0.5921 - val_loss: 0.0144 - val_acc: 0.6831\n",
      "Epoch 48/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0083 - acc: 0.6269 - val_loss: 0.0117 - val_acc: 0.5794\n",
      "Epoch 49/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0075 - acc: 0.5753 - val_loss: 0.0080 - val_acc: 0.5525\n",
      "Epoch 50/50\n",
      "595/595 [==============================] - 4s 7ms/step - loss: 0.0066 - acc: 0.5597 - val_loss: 0.0063 - val_acc: 0.5550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5151337c0>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = EarlyStopping(patience=10)\n",
    "\n",
    "model3.fit(trainGenerator, validation_data= valGenerator, epochs=50, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m model3\u001b[39m.\u001b[39mpredict(testGenerator)\u001b[39m.\u001b[39mround()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m      2\u001b[0m model3\u001b[39m.\u001b[39mevaluate(testGenerator)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(testGenerator).round().astype(int)\n",
    "model3.evaluate(testGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3736,    0],\n",
       "        [   1, 1263]],\n",
       "\n",
       "       [[3765,    0],\n",
       "        [   5, 1230]],\n",
       "\n",
       "       [[3754,    8],\n",
       "        [  37, 1201]],\n",
       "\n",
       "       [[3741,    0],\n",
       "        [   0, 1259]],\n",
       "\n",
       "       [[3724,    0],\n",
       "        [   0, 1276]]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = multilabel_confusion_matrix(y_test.astype(int), y_pred, samplewise=False)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        def1       1.00      1.00      1.00      1264\n",
      "        def2       1.00      1.00      1.00      1235\n",
      "        def3       0.99      0.97      0.98      1238\n",
      "        def4       1.00      1.00      1.00      1259\n",
      "        def5       1.00      1.00      1.00      1276\n",
      "\n",
      "   micro avg       1.00      0.99      1.00      6272\n",
      "   macro avg       1.00      0.99      1.00      6272\n",
      "weighted avg       1.00      0.99      1.00      6272\n",
      " samples avg       0.77      0.77      0.77      6272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.astype(int), y_pred, target_names=['def1','def2','def3','def4','def5'], zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root cause analysis\n",
    "\n",
    "Examining what patterns in the data are related to particular defects\n",
    "\n",
    "1. statistical \n",
    "2. denoising ??\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>defects</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.266296985909937, 0.48574277170495817, 0.36...</td>\n",
       "      <td>[False, False, False, False, True]</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.6106411704068081, 0.9499699673512058, 0.35...</td>\n",
       "      <td>[False, False, False, True, True]</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.6214531835131287, 0.5707332403433221, 0.78...</td>\n",
       "      <td>[False, False, False, False, False]</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.6094422267129465, 0.8629181724700395, 0.44...</td>\n",
       "      <td>[True, False, False, False, True]</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.5072599887415982, 0.766663647815743, 0.325...</td>\n",
       "      <td>[False, True, False, False, False]</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  [[0.266296985909937, 0.48574277170495817, 0.36...   \n",
       "1  [[0.6106411704068081, 0.9499699673512058, 0.35...   \n",
       "2  [[0.6214531835131287, 0.5707332403433221, 0.78...   \n",
       "3  [[0.6094422267129465, 0.8629181724700395, 0.44...   \n",
       "4  [[0.5072599887415982, 0.766663647815743, 0.325...   \n",
       "\n",
       "                               defects  seq_len  \n",
       "0   [False, False, False, False, True]       58  \n",
       "1    [False, False, False, True, True]       51  \n",
       "2  [False, False, False, False, False]       59  \n",
       "3    [True, False, False, False, True]       41  \n",
       "4   [False, True, False, False, False]       47  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.266296985909937, 0.48574277170495817, 0.36...</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.6106411704068081, 0.9499699673512058, 0.35...</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.6214531835131287, 0.5707332403433221, 0.78...</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.6094422267129465, 0.8629181724700395, 0.44...</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.5072599887415982, 0.766663647815743, 0.325...</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  seq_len     d1     d2  \\\n",
       "0  [[0.266296985909937, 0.48574277170495817, 0.36...       58  False  False   \n",
       "1  [[0.6106411704068081, 0.9499699673512058, 0.35...       51  False  False   \n",
       "2  [[0.6214531835131287, 0.5707332403433221, 0.78...       59  False  False   \n",
       "3  [[0.6094422267129465, 0.8629181724700395, 0.44...       41   True  False   \n",
       "4  [[0.5072599887415982, 0.766663647815743, 0.325...       47  False   True   \n",
       "\n",
       "      d3     d4     d5  \n",
       "0  False  False   True  \n",
       "1  False   True   True  \n",
       "2  False  False  False  \n",
       "3  False  False   True  \n",
       "4  False  False  False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects_split = pd.DataFrame(df.defects.to_list(), columns=[f'd{i}' for i in range(1,6)])\n",
    "df = pd.concat([df, defects_split], axis=1).drop('defects', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "727d10f37e7754d0edc8be17e0c092e26977e7ca044c58082825c72261488c48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
